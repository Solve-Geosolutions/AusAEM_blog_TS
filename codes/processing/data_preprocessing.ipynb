{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-6-29\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import matplotlib.patches as patches\n",
    "from tqdm import tqdm\n",
    "from astropy.visualization import simple_norm\n",
    "import pickle\n",
    "\n",
    "from scipy.stats import stats\n",
    "import math\n",
    "import os\n",
    "\n",
    "import datetime\n",
    "datecode = '{}-{}-{}'.format(datetime.datetime.now().year, datetime.datetime.now().month, datetime.datetime.now().day)\n",
    "\n",
    "interim_dir = '/mnt/c/Projects/Blogs/AusAEM_blog_TS/data/interim/'\n",
    "processed_dir = '/mnt/c/Projects/Blogs/AusAEM_blog_TS/data/processed/'\n",
    "raw_dir = '/mnt/c/Projects/Blogs/AusAEM_blog_TS/data/raw/'\n",
    "external_dir = '/mnt/c/Projects/Blogs/AusAEM_blog_TS/data/external/'\n",
    "\n",
    "# make new folders in interim and processed directories for today's date\n",
    "\n",
    "if os.path.join(interim_dir, datecode) not in [x[0] for x in os.walk(interim_dir)]:\n",
    "    os.mkdir(os.path.join(interim_dir, datecode))\n",
    "if os.path.join(processed_dir, datecode) not in [x[0] for x in os.walk(processed_dir)]:\n",
    "    os.mkdir(os.path.join(processed_dir, datecode))\n",
    "\n",
    "print(datecode)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract column headers from dfn file via Mnyikka https://stackoverflow.com/questions/3368969/find-string-between-two-substrings\n",
    "\n",
    "def GetListOfSubstrings(stringSubject,string1,string2):\n",
    "    MyList = []\n",
    "    intstart=0\n",
    "    strlength=len(stringSubject)\n",
    "    continueloop = 1\n",
    "\n",
    "    while(intstart < strlength and continueloop == 1):\n",
    "        intindex1=stringSubject.find(string1,intstart)\n",
    "        if(intindex1 != -1): #The substring was found, lets proceed\n",
    "            intindex1 = intindex1+len(string1)\n",
    "            intindex2 = stringSubject.find(string2,intindex1)\n",
    "            if(intindex2 != -1):\n",
    "                subsequence=stringSubject[intindex1:intindex2]\n",
    "                MyList.append(subsequence)\n",
    "                intstart=intindex2+len(string2)\n",
    "            else:\n",
    "                continueloop=0\n",
    "        else:\n",
    "            continueloop=0\n",
    "    return MyList\n",
    "\n",
    "def interp_along_axis(y, x, newx, axis=1, inverse=False, method='linear'):\n",
    "    \"\"\" Interpolate vertical profiles, e.g. of atmospheric variables\n",
    "    using vectorized numpy operations\n",
    "\n",
    "    This function assumes that the x-xoordinate increases monotonically\n",
    "\n",
    "    #### EDIT BY ####\n",
    "    Thomas Schaap\n",
    "    February 2022\n",
    "    * Updated to take 1Darray for input x and newx\n",
    "    * Updated to 'axis' default = 1, probably breaks if specified otherwise\n",
    "\n",
    "    ps:\n",
    "    * Updated to work with irregularly spaced x-coordinate.\n",
    "    * Updated to work with irregularly spaced newx-coordinate\n",
    "    * Updated to easily inverse the direction of the x-coordinate\n",
    "    * Updated to fill with nans outside extrapolation range\n",
    "    * Updated to include a linear interpolation method as well\n",
    "        (it was initially written for a cubic function)\n",
    "\n",
    "    Peter Kalverla\n",
    "    March 2018\n",
    "\n",
    "    --------------------\n",
    "    More info:\n",
    "    Algorithm from: http://www.paulinternet.nl/?page=bicubic\n",
    "    It approximates y = f(x) = ax^3 + bx^2 + cx + d\n",
    "    where y may be an ndarray input vector\n",
    "    Returns f(newx)\n",
    "\n",
    "    The algorithm uses the derivative f'(x) = 3ax^2 + 2bx + c\n",
    "    and uses the fact that:\n",
    "    f(0) = d\n",
    "    f(1) = a + b + c + d\n",
    "    f'(0) = c\n",
    "    f'(1) = 3a + 2b + c\n",
    "\n",
    "    Rewriting this yields expressions for a, b, c, d:\n",
    "    a = 2f(0) - 2f(1) + f'(0) + f'(1)\n",
    "    b = -3f(0) + 3f(1) - 2f'(0) - f'(1)\n",
    "    c = f'(0)\n",
    "    d = f(0)\n",
    "\n",
    "    These can be evaluated at two neighbouring points in x and\n",
    "    as such constitute the piecewise cubic interpolator.\n",
    "    \"\"\"\n",
    "\n",
    "    x = np.array([np.array(x) for i in np.empty(y.shape[0])])\n",
    "\n",
    "    newx = np.array([np.array(newx) for i in np.empty(y.shape[0])])\n",
    "\n",
    "    # View of x and y with axis as first dimension\n",
    "    if inverse:\n",
    "        _x = np.moveaxis(x, axis, 0)[::-1, ...]\n",
    "        _y = np.moveaxis(y, axis, 0)[::-1, ...]\n",
    "        _newx = np.moveaxis(newx, axis, 0)[::-1, ...]\n",
    "    else:\n",
    "        _y = np.moveaxis(y, axis, 0)\n",
    "        _x = np.moveaxis(x, axis, 0)\n",
    "        _newx = np.moveaxis(newx, axis, 0)\n",
    "\n",
    "    if np.any(np.diff(_x, axis=0) < 0):\n",
    "        raise ValueError('x should increase monotonically')\n",
    "    if np.any(np.diff(_newx, axis=0) < 0):\n",
    "        raise ValueError('newx should increase monotonically')\n",
    "\n",
    "    # Cubic interpolation needs the gradient of y in addition to its values\n",
    "    if method == 'cubic':\n",
    "        # For now, simply use a numpy function to get the derivatives\n",
    "        # This produces the largest memory overhead of the function and\n",
    "        # could alternatively be done in passing.\n",
    "        ydx = np.gradient(_y, axis=0, edge_order=2)\n",
    "\n",
    "    # This will later be concatenated with a dynamic '0th' index\n",
    "    ind = [i for i in np.indices(_y.shape[1:])]\n",
    "\n",
    "    # Allocate the output array\n",
    "    original_dims = _y.shape\n",
    "    newdims = list(original_dims)\n",
    "    newdims[0] = len(_newx)\n",
    "    newy = np.zeros(newdims)\n",
    "\n",
    "    # set initial bounds\n",
    "    i_lower = np.zeros(_x.shape[1:], dtype=int)\n",
    "    i_upper = np.ones(_x.shape[1:], dtype=int)\n",
    "    x_lower = _x[0, ...]\n",
    "    x_upper = _x[1, ...]\n",
    "\n",
    "    for i, xi in enumerate(_newx):\n",
    "        # Start at the 'bottom' of the array and work upwards\n",
    "        # This only works if x and newx increase monotonically\n",
    "\n",
    "        # Update bounds where necessary and possible\n",
    "        needs_update = (xi > x_upper) & (i_upper+1<len(_x))\n",
    "        # print x_upper.max(), np.any(needs_update)\n",
    "        while np.any(needs_update):\n",
    "            i_lower = np.where(needs_update, i_lower+1, i_lower)\n",
    "            i_upper = i_lower + 1\n",
    "            x_lower = _x[[i_lower]+ind]\n",
    "            x_upper = _x[[i_upper]+ind]\n",
    "\n",
    "            # Check again\n",
    "            needs_update = (xi > x_upper) & (i_upper+1<len(_x))\n",
    "\n",
    "        # Express the position of xi relative to its neighbours\n",
    "        xj = (xi-x_lower)/(x_upper - x_lower)\n",
    "\n",
    "        # Determine where there is a valid interpolation range\n",
    "        within_bounds = (_x[0, ...] < xi) & (xi < _x[-1, ...])\n",
    "\n",
    "        if method == 'linear':\n",
    "            f0, f1 = _y[[i_lower]+ind], _y[[i_upper]+ind]\n",
    "            a = f1 - f0\n",
    "            b = f0\n",
    "\n",
    "            newy[i, ...] = np.where(within_bounds, a*xj+b, np.nan)\n",
    "\n",
    "        elif method=='cubic':\n",
    "            f0, f1 = _y[[i_lower]+ind], _y[[i_upper]+ind]\n",
    "            df0, df1 = ydx[[i_lower]+ind], ydx[[i_upper]+ind]\n",
    "\n",
    "            a = 2*f0 - 2*f1 + df0 + df1\n",
    "            b = -3*f0 + 3*f1 - 2*df0 - df1\n",
    "            c = df0\n",
    "            d = f0\n",
    "\n",
    "            newy[i, ...] = np.where(within_bounds, a*xj**3 + b*xj**2 + c*xj + d, np.nan)\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"invalid interpolation method\"\n",
    "                             \"(choose 'linear' or 'cubic')\")\n",
    "\n",
    "    if inverse:\n",
    "        newy = newy[::-1, ...]\n",
    "\n",
    "    return np.moveaxis(newy, 0, axis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "QLD_EM_dat_fn = '/mnt/c/Projects/Blogs/AusAEM_blog_TS/data/raw/Final_QLD_Regional_lines/located_data/AusAEM_Year1_QLD_Final_EM.dat'\n",
    "QLD_EM_dfn_fn = '/mnt/c/Projects/Blogs/AusAEM_blog_TS/data/raw/Final_QLD_Regional_lines/located_data/AusAEM_Year1_QLD_Final_EM.dfn'\n",
    "\n",
    "with open(QLD_EM_dfn_fn, 'r') as file:\n",
    "    QLD_EM_dfn = file.read()\n",
    "\n",
    "column_names = GetListOfSubstrings(QLD_EM_dfn, 'RT=;', ':')\n",
    "column_names_list = []\n",
    "for header in column_names:\n",
    "    if header.startswith('EM'):\n",
    "        column_names_list = column_names_list + [header + '[{}]'.format(i) for i in range(1,16)]\n",
    "    else:\n",
    "        column_names_list.append(header)\n",
    "\n",
    "EMZ_HPRG_list = ['EMZ_HPRG' + '[{}]'.format(i) for i in range(1,16)]\n",
    "\n",
    "QLD_EM = pd.read_csv(QLD_EM_dat_fn, header = None, delim_whitespace=True, nrows = 1)\n",
    "QLD_EM.columns = column_names_list\n",
    "\n",
    "select_cols = ['Line', 'Easting', 'Northing'] + EMZ_HPRG_list\n",
    "col_index = []\n",
    "for item in select_cols:\n",
    "    col_index.append(QLD_EM.columns.get_loc(item))\n",
    "\n",
    "QLD_EM = pd.read_csv(QLD_EM_dat_fn, header = None, delim_whitespace=True, usecols = col_index, na_values=-999.999999)\n",
    "\n",
    "QLD_EM.columns = select_cols\n",
    "QLD_EM = QLD_EM.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Line distance calculation, resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 159/159 [01:23<00:00,  1.90it/s]\n"
     ]
    }
   ],
   "source": [
    "# Create along-line distance field\n",
    "\n",
    "append_here = np.array([])\n",
    "for line in tqdm(QLD_EM.Line.unique()):\n",
    "    data = QLD_EM[QLD_EM.Line == line].sort_values('Easting')\n",
    "    array = np.zeros_like(data)\n",
    "    array = array[:,0]\n",
    "    for i in range(len(data)):\n",
    "        if i == 0:\n",
    "            array[i] = 0\n",
    "        else:\n",
    "            array[i] = array[i-1] + np.sqrt(np.abs((data['Easting'].iloc[i] - data['Easting'].iloc[i-1]))**2 + np.abs((data['Northing'].iloc[i] - data['Northing'].iloc[i-1]))**2)\n",
    "    append_here=  np.append(append_here, array)\n",
    "QLD_EM['line_distance'] = append_here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/159 [00:00<?, ?it/s]/home/taschaap/miniconda3/envs/datascience_37/lib/python3.7/site-packages/ipykernel_launcher.py:135: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "/home/taschaap/miniconda3/envs/datascience_37/lib/python3.7/site-packages/ipykernel_launcher.py:122: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "/home/taschaap/miniconda3/envs/datascience_37/lib/python3.7/site-packages/ipykernel_launcher.py:123: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "100%|██████████| 159/159 [01:18<00:00,  2.04it/s]\n"
     ]
    }
   ],
   "source": [
    "# Resample data to consistent 20 m interval\n",
    "\n",
    "x_interval = 20 # m\n",
    "x_interp = np.array([])\n",
    "EMZ_HPRG_interp = []\n",
    "E_interp = []\n",
    "N_interp = []\n",
    "line_list = np.array([])\n",
    "for line in tqdm(QLD_EM.Line.unique()):\n",
    "    data = QLD_EM[QLD_EM.Line == line]\n",
    "    x = QLD_EM[QLD_EM.Line == line]['line_distance']\n",
    "    y = data[EMZ_HPRG_list].values.T\n",
    "    x = data['line_distance']\n",
    "    E = data['Easting']\n",
    "    N = data['Northing']\n",
    "    newx = np.arange(0,x.max(), x_interval)\n",
    "    line_ar = np.full(newx.shape, line)\n",
    "    line_list = np.append(line_list, line_ar)\n",
    "\n",
    "    x_interp = np.append(x_interp, newx)\n",
    "    new_E = np.interp(newx, x, E)\n",
    "    E_interp.append(new_E)\n",
    "\n",
    "    new_N = np.interp(newx, x, N)\n",
    "    N_interp.append(new_N)\n",
    "\n",
    "    new_EMZ_HPRG = interp_along_axis(y, x, newx)\n",
    "    EMZ_HPRG_interp.append(new_EMZ_HPRG)\n",
    "\n",
    "EMZ_HPRG_interp_ar = np.concatenate(EMZ_HPRG_interp, axis =1)\n",
    "new_E_ar = np.concatenate(E_interp)\n",
    "new_N_ar = np.concatenate(N_interp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate dataframe, save csv\n",
    "\n",
    "QLD_interp = pd.DataFrame()\n",
    "QLD_interp['x'] = x_interp\n",
    "QLD_interp['Line'] = line_list.astype(int)\n",
    "QLD_interp['E'] = new_E_ar\n",
    "QLD_interp['N'] = new_N_ar\n",
    "QLD_interp[EMZ_HPRG_list] = pd.DataFrame(EMZ_HPRG_interp_ar.T)\n",
    "QLD_interp = QLD_interp.dropna()\n",
    "\n",
    "QLD_interp.to_csv('/mnt/c/Projects/Blogs/AusAEM_blog_TS/data/processed/QLD_AusEM_interp.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.12 ('datascience_37')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2c4ee8aa3684a5e48d0ee2649853e326efebd9f72f9bd2b5d7b614c002cb51c6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
